// src/jobs/scheduler.js
const axios = require("axios");
const queueService = require("../services/queueService");
const {
  updateQueueSize,
  incJobs,
  observeLatency,
} = require("../api/metrics");

const client = require("prom-client");
const schedulerIntervalGauge = new client.Gauge({
  name: "proxy_scheduler_interval_ms",
  help: "Intervalo atual do scheduler em ms",
});

const UPSTREAM_URL = "https://score.hsborges.dev/api/score";

// ðŸ”¹ Intervalo dinÃ¢mico do scheduler
let interval = 1000; // comeÃ§a com 1s
let timer = setInterval(processQueue, interval);

function adjustScheduler(newInterval) {
  clearInterval(timer);
  interval = newInterval;
  schedulerIntervalGauge.set(interval); // mÃ©trica Prometheus
  timer = setInterval(processQueue, interval);
  console.warn(`[Scheduler] Ajustando cadÃªncia para ${interval}ms`);
}

async function processQueue() {
  const job = await queueService.dequeue();
  if (!job) return;

  const start = Date.now();
  try {
    // ðŸ”¹ Filtra apenas parÃ¢metros vÃ¡lidos para o upstream
    const params = {};
    if (job.params?.cpf) params.cpf = job.params.cpf;

    const response = await axios.get(UPSTREAM_URL, {
      params,
      headers: {
        "client-id": "1", // obrigatÃ³rio
        accept: "application/json",
      },
    });

    incJobs("processed");
    observeLatency((Date.now() - start) / 1000);

    console.log(`[Scheduler] Job ${job.id} processado`, response.data);

    // ðŸ”¹ Se estava em penalidade, volta para 1s
    if (interval > 1000) adjustScheduler(1000);
  } catch (err) {
    incJobs("failed");

    const status = err.response?.status;
    console.error(
      `[Scheduler] Erro no job ${job.id}: status=${status}, msg=${err.message}`
    );

    if (status === 429) {
      // penalidade: aumenta para 3s
      adjustScheduler(3000);
    }
  }
}

// ðŸ”¹ Atualiza a mÃ©trica do tamanho da fila
setInterval(async () => {
  const size = await queueService.size();
  updateQueueSize(size);
}, 2000);

module.exports = { processQueue };
